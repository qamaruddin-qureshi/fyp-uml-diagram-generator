
import json
import random
import os
from sklearn.model_selection import train_test_split

def extract_and_verify():
    print("Loading architecture_training_data.json...")
    input_path = 'architecture_training_data.json'
    if not os.path.exists(input_path):
        print(f"❌ Error: {input_path} not found.")
        return

    with open(input_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    print(f"Total raw items: {len(data)}")

    # 1. Strict Filtering (Must match train_architecture_model.py EXACTLY)
    valid_docs = []
    skipped_count = 0
    
    for item in data:
        if not isinstance(item, dict):
            skipped_count += 1
            continue
        
        # Handle nested structure: architecture_narration can be string or object with 'text' field
        arch_narration = item.get("architecture_narration")
        if arch_narration is None:
            skipped_count += 1
            continue
            
        if isinstance(arch_narration, dict):
            text = arch_narration.get("text", "")
        elif isinstance(arch_narration, str):
            text = arch_narration
        else:
            skipped_count += 1
            continue
        
        if not text or not text.strip():
            skipped_count += 1
            continue
        
        # Skip template entries
        if "TEMPLATE" in text or "[COMPONENT_NAME]" in text:
            skipped_count += 1
            continue
            
        # If passed all checks, it's a valid document for the model
        valid_docs.append(item)

    print(f"Valid documents after filtering: {len(valid_docs)}")
    print(f"Skipped documents: {skipped_count}")

    if not valid_docs:
        print("❌ No valid documents found.")
        return

    # 2. Replicate Training Split
    print("Replicating train_test_split (test_size=0.2, random_state=42)...")
    # doc_bin uses the doc objects, here we use the raw items, but the indices/order 
    # must be preserved if we want to be exact. train_test_split shuffles by default.
    # As long as the input list and random_state are the same, the split is deterministic.
    train_data, test_data = train_test_split(valid_docs, test_size=0.2, random_state=42)

    print(f"Train size: {len(train_data)}")
    print(f"Test size: {len(test_data)}")

    # 3. Strict Verification
    print("\nVerifying split integrity...")
    # Using narration text as a signature
    def get_text(item):
        n = item['architecture_narration']
        return n.get('text', "") if isinstance(n, dict) else n


    train_signatures = {json.dumps(get_text(item)) for item in train_data}
    test_signatures = {json.dumps(get_text(item)) for item in test_data}

    overlap = train_signatures.intersection(test_signatures)
    
    if overlap:
        print(f"[CRITICAL WARNING] Found {len(overlap)} overlapping items between Train and Test sets!")
        print("Filtering these out from the test candidate pool to ensure zero contamination...")
        
        # Filter test_data to keep only those NOT in train_signatures
        clean_test_data = [
            item for item in test_data 
            if json.dumps(get_text(item)) not in train_signatures
        ]
        print(f"Original Test Size: {len(test_data)}")
        print(f"Clean Test Size: {len(clean_test_data)}")
        
        if not clean_test_data:
            print("[ERROR] No unique test data remaining after filtering!")
            return
            
        test_data = clean_test_data
    else:
        print("[SUCCESS] No overlap detected. Test set is strictly unseen data.")

    # 4. Select Subset (30 items)
    # We want a mix of component and deployment if possible, but most narrations cover both.
    random.seed(42) 
    subset = random.sample(test_data, min(30, len(test_data)))
    
    print(f"\nSelected {len(subset)} items for the test subset.")

    # 5. Generate structural_test_data.py content
    output_path = os.path.join('user_stories', 'structural_test_data.py')
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write("# Auto-generated test data subset from Architecture Dev Split\n")
        f.write("# This file is generated by scripts/extract_test_data.py\n")
        f.write("# Do not edit manually if you want to stay in sync with the split.\n\n")
        
        f.write("COMPONENT_TEST_DATA = [\n")
        for i, item in enumerate(subset):
            narration = get_text(item)
            f.write(f"    {{\n")
            f.write(f"        'id': {i+1},\n") 
            f.write(f"        'narration': {json.dumps(narration)},\n")
            f.write(f"    }},\n")
        f.write("]\n\n")
        
        f.write("DEPLOYMENT_TEST_DATA = [\n")
        for i, item in enumerate(subset):
             # Deep copy logic: typically deployment is the same narration or potentially filtered.
             # For now we assume the architecture narration covers deployment too.
            narration = get_text(item)
            f.write(f"    {{\n")
            f.write(f"        'id': {i+1},\n")
            f.write(f"        'narration': {json.dumps(narration)},\n")
            f.write(f"    }},\n")
        f.write("]\n")

    print(f"[SUCCESS] Saved test subset to {output_path}")

if __name__ == "__main__":
    extract_and_verify()
